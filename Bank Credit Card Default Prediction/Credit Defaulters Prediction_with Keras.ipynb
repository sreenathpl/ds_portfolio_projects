{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREDICT DEFAULTERS PREDICTION USING KERAS IN PYTHON\n",
    "\n",
    "The dataset belongs to TW banking system. Our aim here is to predict the credit defaulters with certain known parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Python\\Anaconda_1\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the working directory\n",
    "os.chdir(\"C:\\\\Users\\\\320\\\\Python\\\\Keras\\\\\")\n",
    "os.getcwd()\n",
    "# importing the dataset\n",
    "TW_data = pd.read_csv(\"UCI_Credit_Card.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15000.500000</td>\n",
       "      <td>167484.322667</td>\n",
       "      <td>1.603733</td>\n",
       "      <td>1.853133</td>\n",
       "      <td>1.551867</td>\n",
       "      <td>35.485500</td>\n",
       "      <td>-0.016700</td>\n",
       "      <td>-0.133767</td>\n",
       "      <td>-0.166200</td>\n",
       "      <td>-0.220667</td>\n",
       "      <td>...</td>\n",
       "      <td>43262.948967</td>\n",
       "      <td>40311.400967</td>\n",
       "      <td>38871.760400</td>\n",
       "      <td>5663.580500</td>\n",
       "      <td>5.921163e+03</td>\n",
       "      <td>5225.68150</td>\n",
       "      <td>4826.076867</td>\n",
       "      <td>4799.387633</td>\n",
       "      <td>5215.502567</td>\n",
       "      <td>0.221200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8660.398374</td>\n",
       "      <td>129747.661567</td>\n",
       "      <td>0.489129</td>\n",
       "      <td>0.790349</td>\n",
       "      <td>0.521970</td>\n",
       "      <td>9.217904</td>\n",
       "      <td>1.123802</td>\n",
       "      <td>1.197186</td>\n",
       "      <td>1.196868</td>\n",
       "      <td>1.169139</td>\n",
       "      <td>...</td>\n",
       "      <td>64332.856134</td>\n",
       "      <td>60797.155770</td>\n",
       "      <td>59554.107537</td>\n",
       "      <td>16563.280354</td>\n",
       "      <td>2.304087e+04</td>\n",
       "      <td>17606.96147</td>\n",
       "      <td>15666.159744</td>\n",
       "      <td>15278.305679</td>\n",
       "      <td>17777.465775</td>\n",
       "      <td>0.415062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-170000.000000</td>\n",
       "      <td>-81334.000000</td>\n",
       "      <td>-339603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7500.750000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2326.750000</td>\n",
       "      <td>1763.000000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>8.330000e+02</td>\n",
       "      <td>390.00000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>252.500000</td>\n",
       "      <td>117.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15000.500000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19052.000000</td>\n",
       "      <td>18104.500000</td>\n",
       "      <td>17071.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1800.00000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22500.250000</td>\n",
       "      <td>240000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54506.000000</td>\n",
       "      <td>50190.500000</td>\n",
       "      <td>49198.250000</td>\n",
       "      <td>5006.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4505.00000</td>\n",
       "      <td>4013.250000</td>\n",
       "      <td>4031.500000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>891586.000000</td>\n",
       "      <td>927171.000000</td>\n",
       "      <td>961664.000000</td>\n",
       "      <td>873552.000000</td>\n",
       "      <td>1.684259e+06</td>\n",
       "      <td>896040.00000</td>\n",
       "      <td>621000.000000</td>\n",
       "      <td>426529.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID       LIMIT_BAL           SEX     EDUCATION      MARRIAGE  \\\n",
       "count  30000.000000    30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean   15000.500000   167484.322667      1.603733      1.853133      1.551867   \n",
       "std     8660.398374   129747.661567      0.489129      0.790349      0.521970   \n",
       "min        1.000000    10000.000000      1.000000      0.000000      0.000000   \n",
       "25%     7500.750000    50000.000000      1.000000      1.000000      1.000000   \n",
       "50%    15000.500000   140000.000000      2.000000      2.000000      2.000000   \n",
       "75%    22500.250000   240000.000000      2.000000      2.000000      2.000000   \n",
       "max    30000.000000  1000000.000000      2.000000      6.000000      3.000000   \n",
       "\n",
       "                AGE         PAY_0         PAY_2         PAY_3         PAY_4  \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean      35.485500     -0.016700     -0.133767     -0.166200     -0.220667   \n",
       "std        9.217904      1.123802      1.197186      1.196868      1.169139   \n",
       "min       21.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
       "25%       28.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "50%       34.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       41.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       79.000000      8.000000      8.000000      8.000000      8.000000   \n",
       "\n",
       "                  ...                  BILL_AMT4      BILL_AMT5  \\\n",
       "count             ...               30000.000000   30000.000000   \n",
       "mean              ...               43262.948967   40311.400967   \n",
       "std               ...               64332.856134   60797.155770   \n",
       "min               ...             -170000.000000  -81334.000000   \n",
       "25%               ...                2326.750000    1763.000000   \n",
       "50%               ...               19052.000000   18104.500000   \n",
       "75%               ...               54506.000000   50190.500000   \n",
       "max               ...              891586.000000  927171.000000   \n",
       "\n",
       "           BILL_AMT6       PAY_AMT1      PAY_AMT2      PAY_AMT3  \\\n",
       "count   30000.000000   30000.000000  3.000000e+04   30000.00000   \n",
       "mean    38871.760400    5663.580500  5.921163e+03    5225.68150   \n",
       "std     59554.107537   16563.280354  2.304087e+04   17606.96147   \n",
       "min   -339603.000000       0.000000  0.000000e+00       0.00000   \n",
       "25%      1256.000000    1000.000000  8.330000e+02     390.00000   \n",
       "50%     17071.000000    2100.000000  2.009000e+03    1800.00000   \n",
       "75%     49198.250000    5006.000000  5.000000e+03    4505.00000   \n",
       "max    961664.000000  873552.000000  1.684259e+06  896040.00000   \n",
       "\n",
       "            PAY_AMT4       PAY_AMT5       PAY_AMT6  default.payment.next.month  \n",
       "count   30000.000000   30000.000000   30000.000000                30000.000000  \n",
       "mean     4826.076867    4799.387633    5215.502567                    0.221200  \n",
       "std     15666.159744   15278.305679   17777.465775                    0.415062  \n",
       "min         0.000000       0.000000       0.000000                    0.000000  \n",
       "25%       296.000000     252.500000     117.750000                    0.000000  \n",
       "50%      1500.000000    1500.000000    1500.000000                    0.000000  \n",
       "75%      4013.250000    4031.500000    4000.000000                    0.000000  \n",
       "max    621000.000000  426529.000000  528666.000000                    1.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TW_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNDERSTANDING THE DATA\n",
    "The first column mentions the customer ID. The IDs are unique and we will not need it to predict the outcome as it does not provide any information regarding the credit defaulting.Hence let us consider only the rest of the data. \n",
    "\n",
    "There are 23 other independent variables which are a combination of categoriical and numeric variables. The dependent varaible is binary shows whether the customer is a credit defaulter or not.\n",
    "\n",
    "As the dependent variable is categorical this becomes a classification problem. In this exercise we use Keras to build an ANN in order to predict the credit defaulters.\n",
    "\n",
    "As a first step we deeply take a look at the data and perform our EDA before proceeding with the modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.0000e+04 2.0000e+00 2.0000e+00 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [1.2000e+05 2.0000e+00 2.0000e+00 ... 1.0000e+03 0.0000e+00 2.0000e+03]\n",
      " [9.0000e+04 2.0000e+00 2.0000e+00 ... 1.0000e+03 1.0000e+03 5.0000e+03]\n",
      " ...\n",
      " [3.0000e+04 1.0000e+00 2.0000e+00 ... 4.2000e+03 2.0000e+03 3.1000e+03]\n",
      " [8.0000e+04 1.0000e+00 3.0000e+00 ... 1.9260e+03 5.2964e+04 1.8040e+03]\n",
      " [5.0000e+04 1.0000e+00 2.0000e+00 ... 1.0000e+03 1.0000e+03 1.0000e+03]]\n",
      "[1 1 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# removing the customer id and name and saving the dependent varaibles 1n x\n",
    "x = TW_data.iloc[:,1:24].values\n",
    "\n",
    "# saving the independent variable in y\n",
    "y = TW_data.iloc[:,24].values\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21000, 23)\n",
      "(21000,)\n",
      "(9000, 23)\n",
      "(9000,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data set into train and test using train_test_split library for cross validation\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# splitting the data in 70:30 ratio\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 111)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the data using the preprocessing library \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.000e+04,  2.000e+00,  3.000e+00,  1.000e+00,  2.500e+01,\n",
       "        -1.000e+00, -1.000e+00, -1.000e+00, -1.000e+00,  0.000e+00,\n",
       "        -1.000e+00,  3.363e+03,  1.740e+02,  1.473e+03,  3.900e+02,\n",
       "         3.900e+02,  7.800e+02,  1.740e+02,  1.473e+03,  7.800e+02,\n",
       "         0.000e+00,  7.800e+02,  0.000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL BUILDING USING KERAS\n",
    "\n",
    "We have so far understood the data and made some preprocessing on the data in order to make the data suitable for our model. Now that our data is ready to be trained let us build our first Keras model.\n",
    "\n",
    "We are here using a sequential model from the Keras as the data is simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required modules from keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1:  initializing our model\n",
    "class_model_keras = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Python\\Anaconda_1\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=23, activation=\"relu\", units=12, kernel_initializer=\"uniform\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "G:\\Python\\Anaconda_1\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=12, kernel_initializer=\"uniform\")`\n",
      "G:\\Python\\Anaconda_1\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Adding the layers to our NN. \n",
    "# In this step we add 1 i/p layer(which are the ips directly), multiple hidden layers & 1 o/p layer\n",
    "# As there are 23 input variables there will be 23 nodes in the input layer\n",
    "# Nodes in the hidden layer is free to our choice, however to have an optinum error\n",
    "# we can calculate the nodes in our first hidden layer to be (I/p nodes + 1 )/2 = (23+1)/2 = 12\n",
    "\n",
    "# While initializing random weights to the NN, \n",
    "# we pass the value to the hyperparameter init as \"UNIFORM\"\n",
    "# UNIFORM will ensure that the weights are given uniformly random and close to 0\n",
    "\n",
    "# Also we would be specifying what activation function to be used. LEt us use RELU in our model here\n",
    "\n",
    "\n",
    "# 1st HIDDEN LAYER\n",
    "class_model_keras.add(Dense(input_dim = 23, output_dim = 12, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# 2nd Hidden Layer \n",
    "# as the input dim to this layer is the output from the previous layer \n",
    "# we need not explicitly specify it here\n",
    "class_model_keras.add(Dense(output_dim = 12, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# OUTPUT LAYER\n",
    "# sigmoid activation is used to get the outout between 0 and 1.\n",
    "class_model_keras.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: COMPILING THE NEURAL NETWORK\n",
    "# In this step we have the liberty to choose the optimization method we would like to use \n",
    "# the loss fucntion and the metrics that we require ad outpur\n",
    "# binary_crossentropy loss function used when a binary output is expected\n",
    "\n",
    "class_model_keras.compile(optimizer='sgd', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  880/21000 [>.............................] - ETA: 3s - loss: 0.7616 - acc: 0.7886"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Python\\Anaconda_1\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 3s 131us/step - loss: 0.5915 - acc: 0.7684\n",
      "Epoch 2/100\n",
      "21000/21000 [==============================] - 3s 128us/step - loss: 0.5426 - acc: 0.7749\n",
      "Epoch 3/100\n",
      "21000/21000 [==============================] - 3s 139us/step - loss: 0.5244 - acc: 0.7763\n",
      "Epoch 4/100\n",
      "21000/21000 [==============================] - 3s 128us/step - loss: 0.4798 - acc: 0.7972\n",
      "Epoch 5/100\n",
      "21000/21000 [==============================] - 3s 145us/step - loss: 0.4627 - acc: 0.8078\n",
      "Epoch 6/100\n",
      "21000/21000 [==============================] - 3s 145us/step - loss: 0.4566 - acc: 0.8113\n",
      "Epoch 7/100\n",
      "21000/21000 [==============================] - 3s 134us/step - loss: 0.4529 - acc: 0.8139\n",
      "Epoch 8/100\n",
      "21000/21000 [==============================] - 3s 130us/step - loss: 0.4526 - acc: 0.8136\n",
      "Epoch 9/100\n",
      "21000/21000 [==============================] - 3s 130us/step - loss: 0.4486 - acc: 0.8160\n",
      "Epoch 10/100\n",
      "21000/21000 [==============================] - 3s 128us/step - loss: 0.4471 - acc: 0.8151\n",
      "Epoch 11/100\n",
      "21000/21000 [==============================] - 3s 146us/step - loss: 0.4459 - acc: 0.8151\n",
      "Epoch 12/100\n",
      "21000/21000 [==============================] - 3s 145us/step - loss: 0.4445 - acc: 0.8169\n",
      "Epoch 13/100\n",
      "21000/21000 [==============================] - 3s 134us/step - loss: 0.4433 - acc: 0.8160\n",
      "Epoch 14/100\n",
      "21000/21000 [==============================] - 3s 135us/step - loss: 0.4427 - acc: 0.8172\n",
      "Epoch 15/100\n",
      "21000/21000 [==============================] - 3s 134us/step - loss: 0.4421 - acc: 0.8161\n",
      "Epoch 16/100\n",
      "21000/21000 [==============================] - 3s 141us/step - loss: 0.4414 - acc: 0.8164\n",
      "Epoch 17/100\n",
      "21000/21000 [==============================] - 3s 145us/step - loss: 0.4402 - acc: 0.8164\n",
      "Epoch 18/100\n",
      "21000/21000 [==============================] - 3s 134us/step - loss: 0.4401 - acc: 0.8170\n",
      "Epoch 19/100\n",
      "21000/21000 [==============================] - 3s 128us/step - loss: 0.4395 - acc: 0.8169\n",
      "Epoch 20/100\n",
      "21000/21000 [==============================] - 3s 129us/step - loss: 0.4386 - acc: 0.8180\n",
      "Epoch 21/100\n",
      "21000/21000 [==============================] - 3s 128us/step - loss: 0.4378 - acc: 0.8175\n",
      "Epoch 22/100\n",
      "21000/21000 [==============================] - 3s 144us/step - loss: 0.4373 - acc: 0.8177\n",
      "Epoch 23/100\n",
      "21000/21000 [==============================] - 3s 143us/step - loss: 0.4376 - acc: 0.8189\n",
      "Epoch 24/100\n",
      "21000/21000 [==============================] - 3s 134us/step - loss: 0.4370 - acc: 0.8188\n",
      "Epoch 25/100\n",
      "21000/21000 [==============================] - 3s 135us/step - loss: 0.4365 - acc: 0.8190\n",
      "Epoch 26/100\n",
      "21000/21000 [==============================] - 3s 130us/step - loss: 0.4361 - acc: 0.8188\n",
      "Epoch 27/100\n",
      "21000/21000 [==============================] - 3s 129us/step - loss: 0.4357 - acc: 0.8193\n",
      "Epoch 28/100\n",
      "21000/21000 [==============================] - 3s 150us/step - loss: 0.4356 - acc: 0.8198\n",
      "Epoch 29/100\n",
      "21000/21000 [==============================] - 3s 138us/step - loss: 0.4351 - acc: 0.8182\n",
      "Epoch 30/100\n",
      "21000/21000 [==============================] - 3s 131us/step - loss: 0.4345 - acc: 0.8194\n",
      "Epoch 31/100\n",
      "21000/21000 [==============================] - 3s 139us/step - loss: 0.4339 - acc: 0.8194\n",
      "Epoch 32/100\n",
      "21000/21000 [==============================] - 3s 166us/step - loss: 0.4335 - acc: 0.8196\n",
      "Epoch 33/100\n",
      "21000/21000 [==============================] - 3s 148us/step - loss: 0.4337 - acc: 0.8192\n",
      "Epoch 34/100\n",
      "21000/21000 [==============================] - 3s 141us/step - loss: 0.4328 - acc: 0.8201\n",
      "Epoch 35/100\n",
      "21000/21000 [==============================] - 3s 132us/step - loss: 0.4327 - acc: 0.8196\n",
      "Epoch 36/100\n",
      "21000/21000 [==============================] - 3s 131us/step - loss: 0.4330 - acc: 0.8198\n",
      "Epoch 37/100\n",
      "21000/21000 [==============================] - 3s 133us/step - loss: 0.4327 - acc: 0.8203\n",
      "Epoch 38/100\n",
      "21000/21000 [==============================] - 3s 135us/step - loss: 0.4321 - acc: 0.8198\n",
      "Epoch 39/100\n",
      "21000/21000 [==============================] - 3s 154us/step - loss: 0.4316 - acc: 0.8203\n",
      "Epoch 40/100\n",
      "21000/21000 [==============================] - 3s 143us/step - loss: 0.4318 - acc: 0.8198\n",
      "Epoch 41/100\n",
      "21000/21000 [==============================] - 3s 135us/step - loss: 0.4312 - acc: 0.8200\n",
      "Epoch 42/100\n",
      "21000/21000 [==============================] - 3s 136us/step - loss: 0.4311 - acc: 0.8194\n",
      "Epoch 43/100\n",
      "21000/21000 [==============================] - 3s 136us/step - loss: 0.4308 - acc: 0.8204\n",
      "Epoch 44/100\n",
      "21000/21000 [==============================] - 3s 154us/step - loss: 0.4311 - acc: 0.8204\n",
      "Epoch 45/100\n",
      "21000/21000 [==============================] - 3s 155us/step - loss: 0.4306 - acc: 0.8193\n",
      "Epoch 46/100\n",
      "21000/21000 [==============================] - 3s 153us/step - loss: 0.4298 - acc: 0.8201\n",
      "Epoch 47/100\n",
      "21000/21000 [==============================] - 3s 138us/step - loss: 0.4303 - acc: 0.8188\n",
      "Epoch 48/100\n",
      "21000/21000 [==============================] - 3s 138us/step - loss: 0.4296 - acc: 0.8203 0s - loss: 0.4292 - acc:\n",
      "Epoch 49/100\n",
      "21000/21000 [==============================] - 3s 163us/step - loss: 0.4297 - acc: 0.8204\n",
      "Epoch 50/100\n",
      "21000/21000 [==============================] - 3s 140us/step - loss: 0.4300 - acc: 0.8210\n",
      "Epoch 51/100\n",
      "21000/21000 [==============================] - 3s 123us/step - loss: 0.4297 - acc: 0.8197\n",
      "Epoch 52/100\n",
      "21000/21000 [==============================] - 3s 120us/step - loss: 0.4293 - acc: 0.8201\n",
      "Epoch 53/100\n",
      "21000/21000 [==============================] - 2s 119us/step - loss: 0.4293 - acc: 0.8203\n",
      "Epoch 54/100\n",
      "21000/21000 [==============================] - 2s 112us/step - loss: 0.4284 - acc: 0.8200\n",
      "Epoch 55/100\n",
      "21000/21000 [==============================] - 3s 130us/step - loss: 0.4289 - acc: 0.8202\n",
      "Epoch 56/100\n",
      "21000/21000 [==============================] - 3s 126us/step - loss: 0.4290 - acc: 0.8204\n",
      "Epoch 57/100\n",
      "21000/21000 [==============================] - 2s 116us/step - loss: 0.4284 - acc: 0.8193\n",
      "Epoch 58/100\n",
      "21000/21000 [==============================] - 2s 111us/step - loss: 0.4285 - acc: 0.8194\n",
      "Epoch 59/100\n",
      "21000/21000 [==============================] - 2s 113us/step - loss: 0.4288 - acc: 0.8200\n",
      "Epoch 60/100\n",
      "21000/21000 [==============================] - 2s 112us/step - loss: 0.4283 - acc: 0.8218\n",
      "Epoch 61/100\n",
      "21000/21000 [==============================] - 3s 119us/step - loss: 0.4282 - acc: 0.8205\n",
      "Epoch 62/100\n",
      "21000/21000 [==============================] - 3s 133us/step - loss: 0.4279 - acc: 0.8207\n",
      "Epoch 63/100\n",
      "21000/21000 [==============================] - 3s 120us/step - loss: 0.4278 - acc: 0.8205\n",
      "Epoch 64/100\n",
      "21000/21000 [==============================] - 2s 113us/step - loss: 0.4277 - acc: 0.8203\n",
      "Epoch 65/100\n",
      "21000/21000 [==============================] - 2s 113us/step - loss: 0.4277 - acc: 0.8215\n",
      "Epoch 66/100\n",
      "21000/21000 [==============================] - 2s 114us/step - loss: 0.4275 - acc: 0.8205\n",
      "Epoch 67/100\n",
      "21000/21000 [==============================] - 2s 113us/step - loss: 0.4276 - acc: 0.8205\n",
      "Epoch 68/100\n",
      "21000/21000 [==============================] - 4s 193us/step - loss: 0.4270 - acc: 0.8188\n",
      "Epoch 69/100\n",
      "21000/21000 [==============================] - 5s 228us/step - loss: 0.4270 - acc: 0.8203\n",
      "Epoch 70/100\n",
      "21000/21000 [==============================] - 3s 161us/step - loss: 0.4269 - acc: 0.8206\n",
      "Epoch 71/100\n",
      "21000/21000 [==============================] - 3s 143us/step - loss: 0.4271 - acc: 0.8197\n",
      "Epoch 72/100\n",
      "21000/21000 [==============================] - 4s 167us/step - loss: 0.4267 - acc: 0.8196\n",
      "Epoch 73/100\n",
      "21000/21000 [==============================] - 3s 159us/step - loss: 0.4271 - acc: 0.8216\n",
      "Epoch 74/100\n",
      "21000/21000 [==============================] - 3s 147us/step - loss: 0.4272 - acc: 0.8203\n",
      "Epoch 75/100\n",
      "21000/21000 [==============================] - 3s 148us/step - loss: 0.4264 - acc: 0.8210\n",
      "Epoch 76/100\n",
      "21000/21000 [==============================] - 3s 152us/step - loss: 0.4266 - acc: 0.8207\n",
      "Epoch 77/100\n",
      "21000/21000 [==============================] - 4s 169us/step - loss: 0.4261 - acc: 0.8198\n",
      "Epoch 78/100\n",
      "21000/21000 [==============================] - 3s 158us/step - loss: 0.4265 - acc: 0.8205\n",
      "Epoch 79/100\n",
      "21000/21000 [==============================] - 3s 147us/step - loss: 0.4261 - acc: 0.8213\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 3s 135us/step - loss: 0.4261 - acc: 0.8213\n",
      "Epoch 81/100\n",
      "21000/21000 [==============================] - 3s 137us/step - loss: 0.4261 - acc: 0.8215\n",
      "Epoch 82/100\n",
      "21000/21000 [==============================] - 3s 152us/step - loss: 0.4263 - acc: 0.8211\n",
      "Epoch 83/100\n",
      "21000/21000 [==============================] - 3s 156us/step - loss: 0.4259 - acc: 0.8209\n",
      "Epoch 84/100\n",
      "21000/21000 [==============================] - 3s 145us/step - loss: 0.4259 - acc: 0.8209\n",
      "Epoch 85/100\n",
      "21000/21000 [==============================] - 3s 142us/step - loss: 0.4263 - acc: 0.8206\n",
      "Epoch 86/100\n",
      "21000/21000 [==============================] - 3s 142us/step - loss: 0.4255 - acc: 0.8208\n",
      "Epoch 87/100\n",
      "21000/21000 [==============================] - 3s 146us/step - loss: 0.4256 - acc: 0.8214\n",
      "Epoch 88/100\n",
      "21000/21000 [==============================] - 3s 158us/step - loss: 0.4259 - acc: 0.8209\n",
      "Epoch 89/100\n",
      "21000/21000 [==============================] - 3s 145us/step - loss: 0.4255 - acc: 0.8209\n",
      "Epoch 90/100\n",
      "21000/21000 [==============================] - 3s 138us/step - loss: 0.4255 - acc: 0.8202\n",
      "Epoch 91/100\n",
      "21000/21000 [==============================] - 3s 139us/step - loss: 0.4255 - acc: 0.8201\n",
      "Epoch 92/100\n",
      "21000/21000 [==============================] - 3s 137us/step - loss: 0.4258 - acc: 0.8210\n",
      "Epoch 93/100\n",
      "21000/21000 [==============================] - 3s 162us/step - loss: 0.4251 - acc: 0.8196\n",
      "Epoch 94/100\n",
      "21000/21000 [==============================] - 3s 151us/step - loss: 0.4253 - acc: 0.8206\n",
      "Epoch 95/100\n",
      "21000/21000 [==============================] - 3s 137us/step - loss: 0.4253 - acc: 0.8209\n",
      "Epoch 96/100\n",
      "21000/21000 [==============================] - 3s 139us/step - loss: 0.4252 - acc: 0.8212\n",
      "Epoch 97/100\n",
      "21000/21000 [==============================] - 3s 138us/step - loss: 0.4250 - acc: 0.8207\n",
      "Epoch 98/100\n",
      "21000/21000 [==============================] - 3s 160us/step - loss: 0.4250 - acc: 0.8207\n",
      "Epoch 99/100\n",
      "21000/21000 [==============================] - 3s 152us/step - loss: 0.4250 - acc: 0.8207\n",
      "Epoch 100/100\n",
      "21000/21000 [==============================] - 3s 139us/step - loss: 0.4249 - acc: 0.8211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a4d0f10f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 4: FITTING THE MODEL\n",
    "\n",
    "class_model_keras.fit(x_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: PREDICTING THE RESULTS FOR TEST DATA\n",
    "\n",
    "y_pred =  class_model_keras.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the values are the probabality we may need to set up a threshold to find the actual values\n",
    "\n",
    "pred = (y_pred> 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [ 'no', 'yes']\n",
    "# code from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True')\n",
    "    plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[6612  368]\n",
      " [1285  735]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17a4cec5da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Formulating the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=target_names, normalize=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 31us/step\n",
      "\n",
      "ACCURACY: 81.63%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the Model\n",
    "\n",
    "scores = class_model_keras.evaluate(x_test,y_test)\n",
    "\n",
    "print(\"\\nACCURACY: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION\n",
    "\n",
    "Thus we have built our first model with Keras with 82 % accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
